{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with APIs\n",
    "\n",
    "Python is useful as a tool for interacting with Application Programming Interfaces (APIs). APIs are basically a way for two programs to communicate with one another. One program being perhaps a Python script, the other being a database on the web. \n",
    "\n",
    "Generally, the modern web runs on APIs. Consider the National Weather Service data api, which almost all weather apps use to some extent within their own apps.\n",
    "\n",
    "\"Modern\" APIs are usually [REST](https://www.google.com/search?q=rest+api&rlz=1C1GCEA_enUS886US886&oq=rest+api&aqs=chrome..69i57j0l5j69i60l2.2887j0j4&sourceid=chrome&ie=UTF-8). Older ones are often [SOAP](https://www.google.com/search?q=soap+api&rlz=1C1GCEA_enUS886US886&oq=soap+api&aqs=chrome..69i57j69i59j35i39j0j46j0j69i60j69i61.1352j0j9&sourceid=chrome&ie=UTF-8). REST primarily exchanges data in JSON format (but can also do XML). SOAP exchanges data in XML. \n",
    "\n",
    "REST APIs are *FAR* easier to work with in Python. This is because you can run a query simply with a URL. For example: https://api.crossref.org/works/10.1038/nature02847. The API lives at the base URL, which is https://api.crossref.org/works/. The query parameter in this case is simply the DOI of an article tacked on to the end. But, it can be more complex with multiple parameters. \n",
    "\n",
    "*Tip: if you use Chrome as your browser, there is an extensions named JSON Viewer that formats JSON in your browser to make it easy to read. It's a must for this stuff*\n",
    "\n",
    "Forming the REST query is simple. Just take a string that represents your query parameters and concatenate it to the base URL. Then you can send the message. If you have a list that represents your query parameters, then you can do this in a loop and send them all of one at a time. We'll walk through this below. \n",
    "\n",
    "SOAP APIs work with XML. Rather than sending a query formed as a URL, a SOAP API only accepts queries that are formatted as XML. So, you send an XML message to the API's server and it returns an XML message. In SOAP parlance, you would call this an envelope. You send your query as an XML SOAP envelope, and the response comes back as XML in a SOAP envelope. \n",
    "\n",
    "Forming a SOAP query in an XML envelope is a little more challenging. Fortunately, there are some Python libraries that make this easier. I have used the library SUDS. SUDS bascially takes your parameters and forms the xml envelope behind the scenes and sends the message. \n",
    "\n",
    "#### We can tackle SOAP later. This notebook covers REST. Know that the general concept is the same.\n",
    "\n",
    "The process is:\n",
    "    - Form the query\n",
    "    - send the message\n",
    "    - parse the xml or json response\n",
    "    - write the data into a format that makes sense for us hoomans to read, like a csv\n",
    "    \n",
    "To send the queries, we'll use the [requests](https://requests.readthedocs.io/en/master/) library. Then, we'll use json and csv to work with the response. Aside from sending the requeset, everything covered here was introduced in the earlier notebooks.\n",
    "    \n",
    "    >>> import requests\n",
    "    >>> import json\n",
    "    >>> import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll query the CrossRef API. \n",
    "\n",
    "This API has loads of different search options. See the full documentation [here](https://github.com/CrossRef/rest-api-doc).\n",
    "\n",
    "We'll keep it simple and ask it for information about individual papers via the papers' DOIs.\n",
    "\n",
    "Start by creating a string variable of the base url:\n",
    "    \n",
    "    >>> url = 'https://api.crossref.org/works/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll start with just one paper.\n",
    "\n",
    "    >>> doi = '10.1038/nature02847'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we'll concatenate these two together to form our query:\n",
    "\n",
    "This is super easy!\n",
    "\n",
    "    >>> query = url + doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print it...\n",
    "\n",
    "    >>> print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cool! Jupyter is smart enough to recognize it is a link and displayed it as such.\n",
    "\n",
    "#### Next, we'll use the requests function get() to retrieve the url:\n",
    "\n",
    "    >>> requests.get(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response 200 means it worked. 404 or something else means it went wrong.\n",
    "\n",
    "What we need to do here is store this in a variable:\n",
    "\n",
    "    >>> response = requests.get(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now comes the fun part! \n",
    "We will read the contents of the response as JSON and parse it using the json module.\n",
    "\n",
    "Note that in the previous notebook, we used json.load() to read the json. load() reads data encoded in bytes. But the CrossRef API returns json as string, so we'll use json.loads() instead (The s meaning string).\n",
    "\n",
    "    >>> data = json.loads(response.content.decode('utf-8'))\n",
    "    \n",
    "*Note: response.content means we're reading the content of the response. .decode means we're reading it as a string encoded in utf-8. Encoding is a frequent issue when dealing with string data. Reading and writing it in utf-8 ensures unusual characters like diacritics and cyrillics don't wreck everything*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nothing happen? Great, that means no errors. \n",
    "\n",
    "run just data to view the json:\n",
    "\n",
    "    >>> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice this JSON is a bit more complex than the book catalog example.\n",
    "\n",
    "#### Time to parse!\n",
    "A good approach is usually to start working through the heirarchy, starting from the top... Try taking a look at some of the different elements. Experiment for a minute:\n",
    "\n",
    "    >>> data['status']\n",
    "    >>> data['publisher']\n",
    "    >>> data['license']\n",
    "    >>> data['message']\n",
    "   \n",
    "    ...etcetera\n",
    "    \n",
    "Remember some of the methods we used previously to access different elements within the hierarchy... *(hint: use index positions)* Refer back to the json notebook for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under what key are the data we're most interested in?\n",
    "\n",
    "    >>> data['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's say we're going after cited references. \n",
    "These are found under ['message']['reference']. So, let's start by storing just the reference key in a variable on its own:\n",
    "\n",
    "    >>> refs = data['message']['reference']\n",
    "    \n",
    "View them:\n",
    "\n",
    "    >>> refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, you could select out the elements of each citation you wish to keep. Perhaps all of them. \n",
    "Notice that CrossRef provides things like the doi of the cited ref, the author (or at least the first author), the year, the journal title (sort of) and then an unstructured full citation. \n",
    "\n",
    "**Create a for loop** that iterates over each cited ref and prints the different elements. Again, this follows the same general concept as the loops we used in previous notebooks to parse XML or JSON:\n",
    "\n",
    "    >>> for ref in refs:\n",
    "            auth = ref['author']\n",
    "            year = ref['year]\n",
    "            journ = ref['journal-title']\n",
    "            vol = ref['volume']\n",
    "            unst = ref['unstructured']\n",
    "            print(auth, year, journ, vol, unst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oh no. Headache time. What happened here?\n",
    "The first three worked fine, and then something went awry. \n",
    "\n",
    "Observe the fourth reference, and note that it does not have author, year, journal, and many other fields. Python couldn't find the author field in the fourth reference, so it threw an error and quit. It does seem to have the unstructured field. \n",
    "\n",
    "#### We'll have to insert some logic into the code using if and else statements. Remember that?\n",
    "\n",
    "Let's test this on some known entities. Create a variable just for reference number 1 (0 index position) and reference 4 (3 index position) and we'll test our logic:\n",
    "\n",
    "    >>> ref1 = refs[0]\n",
    "    >>> ref4 = refs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View them both:\n",
    "\n",
    "    >>> ref1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    >>> ref4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we'll start developing an if else sequence to test if certain elements are present in the reference\n",
    "\n",
    "Start by testing if 'article' is present in ref1. The syntax to check if an element is in a Python dictionary is as follows:\n",
    "\n",
    "    >>> if 'author' in ref1:\n",
    "            print('yes')\n",
    "        else:\n",
    "            print('not present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** There are *many* ways to use [if else sequences in Python](https://www.google.com/search?q=python+if+else+sequence&rlz=1C1GCEA_enUS886US886&oq=python+if+else+sequence&aqs=chrome..69i57.3239j0j4&sourceid=chrome&ie=UTF-8). In our earlier exercise, we tested the value of something using operators, but this time we just checked the presence of a thing.\n",
    "\n",
    "#### Now run the same test on ref4:\n",
    "\n",
    "    >>> if 'author' in ref4:\n",
    "            print('yes')\n",
    "        else:\n",
    "            print('not present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great. We can deploy this general logic sequence when creating variables for each individual element we're parsing.\n",
    "\n",
    "We would say, if present create a variable from the element, if not present, create that variable with a string value of 'NA'\n",
    "\n",
    "    >>> for ref in refs:\n",
    "            if 'author' in ref:\n",
    "                auth = ref['author']\n",
    "            else:\n",
    "                auth = 'NA'\n",
    "        \n",
    "            print(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we just need to build this logic into the rest of the variables we're creating...\n",
    "\n",
    "**Build** the if else sequence into all of the varibles in your loop\n",
    "\n",
    "It will start like this:\n",
    "\n",
    "    >>> for ref in refs:\n",
    "            if 'author' in ref:\n",
    "                auth = ref['author']\n",
    "            else:\n",
    "                auth = 'NA'\n",
    "            \n",
    "            if 'year' in ref:\n",
    "                year = ref['year']\n",
    "            else:\n",
    "                'year' = 'NA'\n",
    "    \n",
    "    etc...\n",
    "        \n",
    "        \n",
    "        print(print(auth, year, journ, vol, unst)\n",
    "        \n",
    "        \n",
    "*Tip: watch your indenting and colons*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem solved--Headache over!\n",
    "\n",
    "Now we just need to wrap this for loop into our csv writer as we have done in earlier notebooks. \n",
    "\n",
    "Try to script a process that will write each citation for a paper into a csv file. \n",
    "\n",
    "## I believe in your success. \n",
    "\n",
    "#### Give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feel like another challenge? \n",
    "\n",
    "#### If that was too #basic try wrapping your parsing loop in another for loop that iterates over a list of four DOIs. Here is a list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "doiList = ['10.1002/2016JE005244',  \n",
    "           '10.1038/s41561-017-0015-2',\n",
    "           '10.1029/2018GL078011',\n",
    "           '10.1002/2017GL074002']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What you'll need to build here is a for loop that will first iterate over each doi, concatenate that doi with the url variable, send each query, read each response as json, then iterate over the response to parse out the elements of the json we want and write it to a csv.\n",
    "\n",
    "You have almost all of the code above to accomplish this, you just need to put it all together.\n",
    "\n",
    "It will start something like this:\n",
    "\n",
    "    >>> for doi in doiList:\n",
    "        ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
